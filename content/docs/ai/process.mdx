---
title: process
---

### AI 对话如何转化为其他用户内容（视频 / 图片 / 代码等）

这是一个“从语言到行动 / 生成”的过程。大致流程如下：

### 🧠 1. 用户意图理解（NLU）
AI 首先通过自然语言处理（NLP/NLU）理解用户的输入：

    - 用户在说什么？

    - 想生成什么类型的内容？（视频 / 图片 / 代码 / 文件等）

    - 有没有附加参数？比如视频时长、图片风格、编程语言等。

>✅ 示例输入：「帮我生成一个展示地球自转的视频，时长10秒。」

### ⚙️ 2. 内容规划与调用模块（中间指令层）
理解完后，系统会构造“中间表示”或“计划”。这可能是：

    - 一段伪代码或逻辑流程（例如：生成脚本、调用工具、组合步骤）

    - 对应某种插件、工具、Agent的 API 调用

    - 对接图像/视频/代码生成模型的参数配置

比如上面示例中，AI 可能内部转换为：
```json
{
  "type": "video_generation",
  "prompt": "Earth rotating in space",
  "duration": 10,
  "style": "realistic"
}
```


### 🖼️ 3. 调用生成模型或工具（执行层）
    - 若是图像：调用图像生成模型（如 DALL·E、Stable Diffusion）

    - 若是视频：调用视频生成模型（如 Runway、Pika Labs、Sora 等）

    - 若是代码：调用代码生成引擎（如 Codex、CodeGen）

    - 若是表格/图表/文件：调用文档结构化模块或绘图工具

这些生成模块可以是`本地的`、`云端的`、也可能是`分布式的 Agent`。

### 📤 4. 结果整合与返回
生成内容返回后：

    - 若是图片/视频：以链接或直接渲染的方式返回

    - 若是代码：可展示为代码块，有时还可运行或预览

    - 若是多步骤内容（比如网页生成+部署）：则逐步返回或展示一个工作流


## AI Agent

AI Agent 指的是具有自主性、目标导向、可感知外界、能行动的 AI 实体，它不是一次性完成任务，而是“持续思考并执行”。

🌟 特征如下：

| 特征            | 说明                          |
| ------------- | --------------------------- |
| 🎯 目标导向       | 有明确目标（如“帮我制定旅行计划”）          |
| 🧠 内部记忆       | 会记住上下文、过程状态                 |
| 🔄 自主推理       | 可拆解任务并自行规划下一步               |
| 🔗 工具接入       | 能调用外部工具、API、插件              |
| 👥 多 Agent 协作 | 可与其他 Agent 协作（例如一个写文案，一个做图） |


## 🧩 示例：让 Agent 完成“创建一个博客网站”的任务

1. 用户说：创建一个博客网站并部署上线。

2. AI Agent 拆分任务：

    - 设计 UI（调用图像生成工具）

    - 编写前端代码（调用代码生成模型）

    - 设置部署流程（调用 DevOps 工具）

    - 上线（调用 Vercel/Netlify 等 API）

3. Agent 在每一步中：

    - 自主决策

    - 调用相关工具

    - 检查结果是否符合预期

    - 决定是否继续或调整参数

    - 这就是 AutoGPT、GPTs、自定义助手等 Agent 系统的基本原理。

总结流程图（简化）

```markdown
用户对话 → 意图理解 → 构造计划 → 调用工具/模型 → 获取结果 → 格式化展示/反馈

                        ↑
                     Agent 控制整个过程，可能持续对话 + 多轮操作

```
